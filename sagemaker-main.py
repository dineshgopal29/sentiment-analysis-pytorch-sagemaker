"""
General Outline

Recall the general outline for SageMaker projects using a notebook instance.

    Download or otherwise retrieve the data.
    Process / Prepare the data.
    Upload the processed data to S3.
    Train a chosen model.
    Test the trained model (typically using a batch transform job).
    Deploy the trained model.
    Use the deployed model.

"""

import os
import glob

def read_imdb_data(data_dir='./data/aclImdb'):
    data = {}
    labels = {}
    
    for data_type in ['train', 'test']:
        print(data_type)
        data[data_type] = {}
        print(data[data_type])
        labels[data_type] = {}
        print(labels[data_type])
        
        for sentiment in ['pos', 'neg']:
            data[data_type][sentiment] = []
            labels[data_type][sentiment] = []
            
            path = os.path.join(data_dir, data_type, sentiment, '*.txt')
            files = glob.glob(path)
            
            for f in files:
                with open(f) as review:
                    data[data_type][sentiment].append(review.read())
                    # Here we represent a positive review by '1' and a negative review by '0'
                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)
                    
            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \
                    "{}/{} data size does not match labels size".format(data_type, sentiment)
                
    return data, labels


data, labels = read_imdb_data()
print("IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg".format(
            len(data['train']['pos']), len(data['train']['neg']),
            len(data['test']['pos']), len(data['test']['neg'])))